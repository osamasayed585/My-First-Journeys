# Android AI Experiment â€” Built with Gemini in Android Studio

This project is part of my personal experiment with **AI-powered Android development** using the latest features in **Android Studio** and **Gemini integration**.

Almost the entire app was generated by Gemini â€” I only made a few small manual edits.  

---

## About the Project

I wanted to test how far Gemini can go in helping Android developers build real apps.  
So I tried creating a simple app with **3 Compose screens**, each showing articles and UI components like **Cards, Icons, and Text**.

I described each screen in plain English â€” and Gemini generated:  
- The full **Compose UI code**  
- **Static data** for each screen  
- **Separate files** for each screen automatically  

In the end, I had a working app without writing almost any code by hand. ðŸ˜„  

---

## Features I Tested

### 1. **Journeys for Android Studio**
Write end-to-end tests using natural language.  
Still a bit slow, but a big step for test automation.

### 2. **From Text to Full Compose Screens**
Describe a screen in English, and Gemini creates it â€” including UI, layout, and data.

### 3. **Automated Dependency Updates**
Gemini can now analyze and update project dependencies automatically, fixing build errors too.

---

## My Thoughts
This experiment showed me how much AI is changing Android development.  
Gemini is not just a chatbot anymore â€” itâ€™s part of the full workflow.  
It helps developers save time, reduce repetitive work, and focus on building better apps.  
